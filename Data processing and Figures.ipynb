{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "import folium\n",
    "import openpyxl\n",
    "import brokenaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Create a directed graph of the Sioux Falls network\n",
    "G = nx.DiGraph()\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Sioux Falls\\\\SiouxFalls_net.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "nodes_df = pd.read_csv(\"C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Sioux Falls\\\\SiouxFalls_node.csv\")\n",
    "\n",
    "# Renaming the columns for clarity\n",
    "nodes_df.columns = ['Node', 'X', 'Y']\n",
    "\n",
    "# Add edges to the graph from the dataframe\n",
    "for _, row in data.iterrows():\n",
    "    G.add_edge(row['A'], row['B'])\n",
    "\n",
    "# Let's add node 1 to the nodes_df with coordinates manually if it's indeed missing\n",
    "nodes_df.loc[len(nodes_df)] = [1, 50000, 510000]\n",
    "\n",
    "# Re-create the position dictionary with the updated nodes dataframe\n",
    "pos = {row['Node']: (row['X'], row['Y']) for index, row in nodes_df.iterrows()}\n",
    "\n",
    "# Remove nodes 13, 20, 21, and 22 from the graph\n",
    "nodes_to_remove = [14, 15, 19, 23, 24]\n",
    "G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "# Convert the graph to a complete graph by adding all missing edges\n",
    "nodes = list(G.nodes())\n",
    "for i in range(len(nodes)):\n",
    "    for j in range(i + 1, len(nodes)):\n",
    "        if not G.has_edge(nodes[i], nodes[j]):\n",
    "            G.add_edge(nodes[i], nodes[j])\n",
    "        if not G.has_edge(nodes[j], nodes[i]):\n",
    "            G.add_edge(nodes[j], nodes[i])\n",
    "\n",
    "# Define the color map for nodes\n",
    "node_color_map = {\n",
    "    1: 'skyblue', 2: 'skyblue', 3: 'skyblue', 4: 'skyblue', 5: 'skyblue', 6: 'skyblue', 7: 'skyblue', 8: 'skyblue', 9: 'skyblue', 10: 'skyblue',\n",
    "    11: 'skyblue', 12: 'skyblue', 13: 'green', 16: 'skyblue', 17: 'skyblue', 18: 'skyblue',\n",
    "    20: 'green', 21: 'green', 22: 'green'\n",
    "}\n",
    "\n",
    "node_colors = [node_color_map.get(node, 'grey') for node in G.nodes()]\n",
    "\n",
    "# Draw the graph with specified coordinates\n",
    "plt.figure(figsize=(14, 12))\n",
    "nx.draw(G, pos, labels={node: int(node) for node in G.nodes()}, node_color=node_colors, edge_color='gray', node_size=1500, font_size=15, font_weight='bold')\n",
    "\n",
    "\n",
    "shelter_patch = mpatches.Patch(color='green', label='Shelters')\n",
    "demand_patch = mpatches.Patch(color='skyblue', label='Demand Points')\n",
    "nothing_patch = mpatches.Patch(color='grey', label='Unused Demand Points')\n",
    "plt.legend(handles=[shelter_patch, demand_patch, nothing_patch], fontsize=16)\n",
    "\n",
    "plt.title('Sioux Falls Network', fontsize=20)\n",
    "plt.savefig('C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Figures\\\\NetworkSF.png', format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the graph with area types\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Create a Zoning Classification graph of the Sioux Falls network\n",
    "G = nx.DiGraph()\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Sioux Falls\\\\SiouxFalls_net.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "nodes_df = pd.read_csv(\"C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Sioux Falls\\\\SiouxFalls_node.csv\")\n",
    "\n",
    "# Renaming the columns for clarity\n",
    "nodes_df.columns = ['Node', 'X', 'Y']\n",
    "\n",
    "# Add edges to the graph from the dataframe\n",
    "for _, row in data.iterrows():\n",
    "    G.add_edge(row['A'], row['B'])\n",
    "\n",
    "# Let's add node 1 to the nodes_df with coordinates manually if it's indeed missing\n",
    "nodes_df.loc[len(nodes_df)] = [1, 50000, 510000]\n",
    "\n",
    "# Re-create the position dictionary with the updated nodes dataframe\n",
    "pos = {row['Node']: (row['X'], row['Y']) for index, row in nodes_df.iterrows()}\n",
    "\n",
    "# Remove nodes 13, 20, 21, and 22 from the graph\n",
    "nodes_to_remove = [14, 15, 19, 23, 24]\n",
    "G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "# Define the new color map for the nodes based on the specified colors\n",
    "node_color_map = {\n",
    "    1: 'red', 2: 'red', 6: 'red', 7: 'red', 8: 'red', 12: 'red', 16: 'red', 18: 'red',\n",
    "    3: 'skyblue', 4: 'skyblue', 10: 'skyblue', 9: 'skyblue',\n",
    "    5: 'orange', 11: 'orange',\n",
    "    17: 'yellow',\n",
    "    13: 'grey', 20: 'grey', 21: 'grey', 22: 'grey'\n",
    "}\n",
    "\n",
    "# Assign colors to nodes, default to grey\n",
    "node_colors = [node_color_map.get(node, 'grey') for node in G.nodes()]\n",
    "\n",
    "nodes = list(G.nodes())\n",
    "for i in range(len(nodes)):\n",
    "    for j in range(i + 1, len(nodes)):\n",
    "        if not G.has_edge(nodes[i], nodes[j]):\n",
    "            G.add_edge(nodes[i], nodes[j])\n",
    "        if not G.has_edge(nodes[j], nodes[i]):\n",
    "            G.add_edge(nodes[j], nodes[i])\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "nx.draw(G, pos, labels={node: int(node) for node in G.nodes()}, with_labels=True, node_color=node_colors, edge_color='gray', node_size=1500, font_size=15, font_weight='bold')\n",
    "\n",
    "home_patch = mpatches.Patch(color='orange', label='Residential Area')\n",
    "leisure_patch = mpatches.Patch(color='yellow', label='Food and Leisure Area')\n",
    "ps_patch = mpatches.Patch(color='skyblue', label='Public Service Area')\n",
    "shop_patch = mpatches.Patch(color='red', label='Commercial and Industrial Area')\n",
    "transport_patch = mpatches.Patch(color = 'green', label = 'Transport Services')\n",
    "shelter_patch = mpatches.Patch(color = 'grey', label = 'Shelters')\n",
    "\n",
    "# Position the legend in the upper right-hand corner\n",
    "plt.legend(handles=[shop_patch, ps_patch, transport_patch, home_patch, leisure_patch, shelter_patch], fontsize=16, loc='upper right')\n",
    "\n",
    "plt.title('', fontsize=16)\n",
    "\n",
    "# Save the figure with proper bounding box adjustments\n",
    "plt.savefig('C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Figures\\\\NetworkZoningSF.png', format='png', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map centered around Birmingham with the filtered data points\n",
    "import pandas as pd\n",
    "import folium\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Create a map centered around Birmingham\n",
    "birmingham_map = folium.Map(location=[52.4862, -1.8904], zoom_start=12)\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Birmingham\\\\node_data.xlsx\"\n",
    "excel_data = pd.read_excel(file_path)\n",
    "\n",
    "# Remove the first row which is likely the header repeated\n",
    "excel_data_clean = excel_data.iloc[1:]\n",
    "\n",
    "# Rename columns for better understanding\n",
    "excel_data_clean.columns = ['NodeID', 'Xcoord', 'Ycoord']\n",
    "\n",
    "# Convert Xcoord and Ycoord to float\n",
    "excel_data_clean['Xcoord'] = excel_data_clean['Xcoord'].astype(float)\n",
    "excel_data_clean['Ycoord'] = excel_data_clean['Ycoord'].astype(float)\n",
    "\n",
    "print(excel_data_clean.head())\n",
    "\n",
    "# Filter data based on specified ranges of x and y coordinates\n",
    "x_min, x_max = 375000, 425000  # Example ranges, modify as needed\n",
    "y_min, y_max = 275000, 310000  # Example ranges, modify as needed\n",
    "\n",
    "filtered_data = excel_data_clean[(excel_data_clean['Xcoord'] >= x_min) & (excel_data_clean['Xcoord'] <= x_max) &\n",
    "                                 (excel_data_clean['Ycoord'] >= y_min) & (excel_data_clean['Ycoord'] <= y_max)]\n",
    "\n",
    "df = filtered_data\n",
    "df.to_excel(\"C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Birmingham\\\\filtered_data.xlsx\")\n",
    "\n",
    "# Redefine the coordinate systems using pyproj for accuracy\n",
    "transformer = Transformer.from_crs(\"epsg:27700\", \"epsg:4326\")\n",
    "\n",
    "# Apply the transformation to each coordinate pair\n",
    "filtered_data['Lat'], filtered_data['Lon'] = zip(*filtered_data.apply(lambda row: transformer.transform(row['Xcoord'], row['Ycoord']), axis=1))\n",
    "\n",
    "# Add points to the map with increased marker size and neon yellow color\n",
    "for idx, row in filtered_data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Lat'], row['Lon']],\n",
    "        radius=5,  # Increased radius for larger points\n",
    "        color='yellow',\n",
    "        fill=True,\n",
    "        fill_color='yellow'\n",
    "    ).add_to(birmingham_map)\n",
    "\n",
    "# Save the updated map as an HTML file\n",
    "map_path = \"C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Birmingham\\\\map_with_points.html\"\n",
    "birmingham_map.save(map_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the results excel files into one\n",
    "def combine_excel_files():\n",
    "    # Create a new workbook for the combined result\n",
    "    combined_workbook = openpyxl.Workbook()\n",
    "    combined_workbook.remove(combined_workbook.active)  # Remove the default sheet created by Workbook\n",
    "\n",
    "    parametervalues = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(16):\n",
    "            file_name = f\"C:\\\\Users\\\\arnau\\\\RTPL_Evac\\\\RTPL_{j}_{i}_Results.xlsx\"\n",
    "            # Load the workbook for the current file\n",
    "            current_workbook = openpyxl.load_workbook(file_name)\n",
    "            \n",
    "            # Copy each sheet from the current workbook to the combined workbook\n",
    "            for sheet_name in current_workbook.sheetnames:\n",
    "                current_sheet = current_workbook[sheet_name]\n",
    "                new_sheet = combined_workbook.create_sheet(title = sheet_name)\n",
    "                \n",
    "                for row in current_sheet.iter_rows():\n",
    "                    for cell in row:\n",
    "                        new_sheet[cell.coordinate] = cell.value\n",
    "\n",
    "    # Save the combined workbook to a new file\n",
    "    combined_workbook.save(\"C:\\\\Users\\\\arnau\\\\RTPL_Evac\\\\Combined_RTPL_Results_SF.xlsx\")    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    combine_excel_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average duration for each parameter value\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of all files uploaded\n",
    "file = \"C:\\\\Users\\\\arnau\\\\RTPL_Evac\\\\Combined_RTPL_Results_SF.xlsx\"\n",
    "\n",
    "\n",
    "# Dictionary to hold the duration times for each X\n",
    "duration_times = {}\n",
    "\n",
    "# Load the Excel file\n",
    "xls = pd.ExcelFile(file)\n",
    "\n",
    "parametervalues = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "\n",
    "# Iterate over each sheet\n",
    "for parameter in range(16):\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        # Check if the sheet name matches the pattern Results_pess\n",
    "        if sheet_name.startswith(f\"Results_{parameter}\"):\n",
    "            # Read the sheet into a DataFrame\n",
    "            df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "            \n",
    "            # Extract the duration times from column G (6th index)\n",
    "            durations = df.iloc[:, 6].dropna().tolist()\n",
    "\n",
    "            # Initialize the list in the dictionary if not already present\n",
    "            if parameter not in duration_times:\n",
    "                duration_times[parameter] = []\n",
    "            \n",
    "            # Append the duration times to the corresponding list\n",
    "            duration_times[parameter].extend(durations)\n",
    "\n",
    "# Calculate the average duration time for each X\n",
    "average_duration_times = {X: sum(times)/len(times) for X, times in duration_times.items() if times}\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "average_duration_df = pd.DataFrame(list(average_duration_times.items()), columns=['Parameter', 'Average Duration'])\n",
    "\n",
    "average_duration_df.to_excel(\"C:\\\\Users\\\\arnau\\\\RTPL_Evac\\\\Average_Duration_Times_SF_RTPL.xlsx\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the individual plots\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the provided Excel file\n",
    "file_path = r\"C:\\Users\\arnau\\RTPL_Evac\\Average_Duration_Times_SF_SRTPL.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Parameter'], df['Objective'], marker='', linestyle='-', color='black', linewidth=2)\n",
    "plt.xlabel(r'$\\rho$', fontsize = 20)  # Increase the font size for the x-axis label\n",
    "plt.ylabel('Total Evacuation Time (min)', fontsize = 20)  # Increase the font size for the y-axis label\n",
    "plt.grid(False)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(450, 600) \n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 15)  # Increase the font size for axis numbers\n",
    "#plt.xticks(range(0,21,2))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"evac_time_SRTPL_SF.png\", format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two images into one\n",
    "from PIL import Image\n",
    "\n",
    "# Paths to the provided images\n",
    "runtime_path = r'C:\\Users\\arnau\\RTPL_Evac\\src\\evac_time_RTPL_RD.png'\n",
    "evacuation_time_path = r'C:\\Users\\arnau\\RTPL_Evac\\src\\runtime_RTPL_RD.png'\n",
    "\n",
    "# Open the images\n",
    "runtime_img = Image.open(runtime_path)\n",
    "evacuation_time_img = Image.open(evacuation_time_path)\n",
    "\n",
    "# Get the dimensions of the images\n",
    "runtime_width, runtime_height = runtime_img.size\n",
    "evacuation_time_width, evacuation_time_height = evacuation_time_img.size\n",
    "\n",
    "# Create a new image with combined width and maximum height\n",
    "total_width = runtime_width + evacuation_time_width\n",
    "max_height = max(runtime_height, evacuation_time_height)\n",
    "combined_img = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "# Paste the images into the combined image\n",
    "combined_img.paste(runtime_img, (0, 0))\n",
    "combined_img.paste(evacuation_time_img, (runtime_width, 0))\n",
    "\n",
    "# Save the combined image\n",
    "combined_path = 'Combined_RTPL_RD.png'\n",
    "combined_img.save(combined_path)\n",
    "\n",
    "# Display the combined image\n",
    "combined_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates from Google My Maps output\n",
    "file_path = 'C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Rotterdam\\\\Rotterdam Network- Shelter Locations.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the coordinates from the 'WKT' column\n",
    "df['longitude'] = df['WKT'].str.extract(r'POINT \\(([^ ]+)')[0].astype(float)\n",
    "df['latitude'] = df['WKT'].str.extract(r'POINT \\([^ ]+ ([^ ]+)\\)')[0].astype(float)\n",
    "\n",
    "# Create a new DataFrame with the extracted coordinates\n",
    "new_df = df[['longitude', 'latitude']]\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "output_file_path = 'C:\\\\Users\\\\arnau\\\\Documents\\\\2023-2024\\\\Bsc2 Thesis\\\\Rotterdam\\\\Rotterdam_Network_Sh_Locations_Coordinates.csv'\n",
    "new_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a complete graph with 4 nodes\n",
    "G = nx.complete_graph(4)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "nx.draw(G, with_labels=True, node_color='lightblue', node_size=500, font_weight='bold', edge_color='gray')\n",
    "plt.title(\"Complete Graph with 4 Nodes\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
